{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPW/k7N45V/QHIGL29DaJCh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pandas numpy anytree"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d0Xo8RW1JuF","executionInfo":{"status":"ok","timestamp":1730130818486,"user_tz":-330,"elapsed":4698,"user":{"displayName":"ANURAG S S","userId":"00496693917842741398"}},"outputId":"2cee3295-9e0d-4b0e-e93b-2912516b93f5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Collecting anytree\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n","Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: anytree\n","Successfully installed anytree-2.12.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4jCj1tr0JSU","executionInfo":{"status":"ok","timestamp":1730130824542,"user_tz":-330,"elapsed":2647,"user":{"displayName":"ANURAG S S","userId":"00496693917842741398"}},"outputId":"fb118e8f-ac4c-40ae-b922-f8966023c311"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset preview:\n","      AGE  INCOME STUDENT     CREDIT BUYS COMPUTER\n","0    <=30    high      no       fair            no\n","1    <=30    high      no  excellent            no\n","2   31…40    high      no       fair           yes\n","3     >40  medium      no       fair           yes\n","4     >40     low     yes       fair           yes\n","5     >40     low     yes  excellent            no\n","6   31…40     low     yes  excellent           yes\n","7    <=30  medium      no       fair            no\n","8    <=30     low     yes       fair           yes\n","9     >40  medium     yes       fair           yes\n","10   <=30  medium     yes  excellent           yes\n","11  31…40  medium      no  excellent           yes\n","12  31…40    high     yes       fair           yes\n","13    >40  medium      no  excellent            no\n","Processed dataset:\n","   AGE INCOME STUDENT CREDIT BUYS COMPUTER\n","0    a      a       a      a             0\n","1    a      a       a      b             0\n","2    b      a       a      a             1\n","3    c      b       a      a             1\n","4    c      c       b      a             1\n","5    c      c       b      b             0\n","6    b      c       b      b             1\n","7    a      b       a      a             0\n","8    a      c       b      a             1\n","9    c      b       b      a             1\n","10   a      b       b      b             1\n","11   b      b       a      b             1\n","12   b      a       b      a             1\n","13   c      b       a      b             0\n","\n","Positive labels: 9, Negative labels: 5\n","\n","Total Count=14\n","\n","Parent entropy=0.9402859586706311\n","Calculating gain for feature 'AGE':\n","Entropy: 0.6935361388961918, Gain: 0.24674981977443933\n","Calculating gain for feature 'INCOME':\n","Entropy: 0.9110633930116763, Gain: 0.02922256565895487\n","Calculating gain for feature 'STUDENT':\n","Entropy: 0.7884504573082896, Gain: 0.15183550136234159\n","Calculating gain for feature 'CREDIT':\n","Entropy: 0.8921589282623617, Gain: 0.04812703040826949\n","\n","Selected feature 'AGE' with maximum gain of 0.24674981977443933\n","\n","Building subtree for 'AGE=a' subset:\n","Subset size: 5, Positive labels: 2, Negative labels: 3\n","Subset entropy: 0.9709505944546686\n","Calculating gain for feature 'INCOME':\n","Entropy: 0.14285714285714285, Gain: 0.8280934515975258\n","Calculating gain for feature 'STUDENT':\n","Entropy: -0.0, Gain: 0.9709505944546686\n","Calculating gain for feature 'CREDIT':\n","Entropy: 0.3396348215831049, Gain: 0.6313157728715637\n","\n","Selected feature 'STUDENT' with maximum gain of 0.9709505944546686\n","\n","Building subtree for 'STUDENT=a' subset:\n","Subset size: 3, Positive labels: 1, Negative labels: 3\n","Subset entropy: 0.5283208335737187\n","Building subtree for 'STUDENT=b' subset:\n","Subset size: 2, Positive labels: 2, Negative labels: 1\n","Subset entropy: 0.5\n","Building subtree for 'AGE=b' subset:\n","Subset size: 4, Positive labels: 4, Negative labels: 1\n","Subset entropy: 0.5\n","Building subtree for 'AGE=c' subset:\n","Subset size: 5, Positive labels: 3, Negative labels: 2\n","Subset entropy: 0.9709505944546686\n","Calculating gain for feature 'INCOME':\n","Entropy: 0.3396348215831049, Gain: 0.6313157728715637\n","Calculating gain for feature 'STUDENT':\n","Entropy: 0.3396348215831049, Gain: 0.6313157728715637\n","Calculating gain for feature 'CREDIT':\n","Entropy: -0.0, Gain: 0.9709505944546686\n","\n","Selected feature 'CREDIT' with maximum gain of 0.9709505944546686\n","\n","Building subtree for 'CREDIT=a' subset:\n","Subset size: 3, Positive labels: 3, Negative labels: 1\n","Subset entropy: 0.5283208335737187\n","Building subtree for 'CREDIT=b' subset:\n","Subset size: 2, Positive labels: 1, Negative labels: 2\n","Subset entropy: 0.5\n","\n","Final Decision Tree:\n","{'AGE': {'a': {'STUDENT': {'a': '0', 'b': '1'}}, 'b': '1', 'c': {'CREDIT': {'a': '1', 'b': '0'}}}}\n","\n","Root\n","└── AGE\n","    ├── a\n","    │   └── STUDENT\n","    │       ├── a\n","    │       │   └── 0\n","    │       └── b\n","    │           └── 1\n","    ├── b\n","    │   └── 1\n","    └── c\n","        └── CREDIT\n","            ├── a\n","            │   └── 1\n","            └── b\n","                └── 0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","file_path = r'/content/dtree.xlsx'\n","df = pd.read_excel(file_path)\n","\n","print(\"Dataset preview:\")\n","print(df)\n","\n","df[\"AGE\"] = df[\"AGE\"].str.replace(r'[^a-zA-Z0-9 ]', '', regex=True)\n","df[\"AGE\"] = df[\"AGE\"].str.replace('30', 'a')\n","df[\"AGE\"] = df[\"AGE\"].str.replace('3140', 'b')\n","df[\"AGE\"] = df[\"AGE\"].str.replace('40', 'c')\n","\n","df[\"INCOME\"] = df[\"INCOME\"].str.replace('high', 'a')\n","df[\"INCOME\"] = df[\"INCOME\"].str.replace('medium', 'b')\n","df[\"INCOME\"] = df[\"INCOME\"].str.replace('low', 'c')\n","\n","df[\"STUDENT\"] = df[\"STUDENT\"].str.replace('no', 'a')\n","df[\"STUDENT\"] = df[\"STUDENT\"].str.replace('yes', 'b')\n","\n","df[\"CREDIT\"] = df[\"CREDIT\"].str.replace('fair', 'a')\n","df[\"CREDIT\"] = df[\"CREDIT\"].str.replace('excellent', 'b')\n","\n","df[\"BUYS COMPUTER\"] = df[\"BUYS COMPUTER\"].str.replace('no', '0')\n","df[\"BUYS COMPUTER\"] = df[\"BUYS COMPUTER\"].str.replace('yes', '1')\n","\n","print(\"Processed dataset:\")\n","print(df)\n","\n","pos = (df['BUYS COMPUTER'] == '1').sum()\n","neg = (df['BUYS COMPUTER'] == '0').sum()\n","\n","print(f\"\\nPositive labels: {pos}, Negative labels: {neg}\")\n","\n","total_count = pos + neg\n","print(f\"\\nTotal Count={total_count}\")\n","\n","parent_entropy = (-(pos / total_count) * np.log2(pos / total_count)\n","                  - (neg / total_count) * np.log2(neg / total_count))\n","print(f\"\\nParent entropy={parent_entropy}\")\n","\n","def calculate_entropy(feature, labels):\n","    pos_count = {'a': 0, 'b': 0, 'c': 0}\n","    neg_count = {'a': 0, 'b': 0, 'c': 0}\n","\n","    pos_feature = feature[labels == '1']\n","    neg_feature = feature[labels == '0']\n","\n","    for m in pos_feature:\n","        words = str(m).split()\n","        for word in words:\n","            if word in pos_count:\n","                pos_count[word] += 1\n","\n","    for m in neg_feature:\n","        words = str(m).split()\n","        for word in words:\n","            if word in neg_count:\n","                neg_count[word] += 1\n","\n","    p_a = pos_count['a'] + neg_count['a']\n","    p_b = pos_count['b'] + neg_count['b']\n","    p_c = pos_count['c'] + neg_count['c']\n","\n","    p_a_1 = (pos_count['a'] / p_a) if p_a > 0 else 0\n","    p_a_2 = (neg_count['a'] / p_a) if p_a > 0 else 0\n","    p_b_1 = (pos_count['b'] / p_b) if p_b > 0 else 0\n","    p_b_2 = (neg_count['b'] / p_b) if p_b > 0 else 0\n","    p_c_1 = (pos_count['c'] / p_c) if p_c > 0 else 0\n","    p_c_2 = (neg_count['c'] / p_c) if p_c > 0 else 0\n","\n","    p_a_1 = p_a_1 if p_a_1 > 0 else 1\n","    p_a_2 = p_a_2 if p_a_2 > 0 else 1\n","    p_b_1 = p_b_1 if p_b_1 > 0 else 1\n","    p_b_2 = p_b_2 if p_b_2 > 0 else 1\n","    p_c_1 = p_c_1 if p_c_1 > 0 else 1\n","    p_c_2 = p_c_2 if p_c_2 > 0 else 1\n","\n","    entropy_feature = (\n","        (p_a / total_count) * (-p_a_1 * np.log2(p_a_1) - p_a_2 * np.log2(p_a_2)) +\n","        (p_b / total_count) * (-p_b_1 * np.log2(p_b_1) - p_b_2 * np.log2(p_b_2)) +\n","        (p_c / total_count) * (-p_c_1 * np.log2(p_c_1) - p_c_2 * np.log2(p_c_2))\n","    )\n","\n","    return entropy_feature\n","\n","features = ['AGE', 'INCOME', 'STUDENT', 'CREDIT']\n","max_gain_feature = None\n","max_gain_value = 0\n","\n","for feature in features:\n","    entropy_feature = calculate_entropy(df[feature], df['BUYS COMPUTER'])\n","    gain_feature = parent_entropy - entropy_feature\n","\n","    if gain_feature > max_gain_value:\n","        max_gain_value = gain_feature\n","        max_gain_feature = feature\n","\n","def split_dataset(df, feature):\n","    splits = {}\n","\n","    for value in df[feature].unique():\n","        splits[value] = df[df[feature] == value]\n","\n","    return splits\n","\n","splits = split_dataset(df, max_gain_feature)\n","\n","def build_tree(df, features, target):\n","    if len(df[target].unique()) == 1:\n","        return df[target].iloc[0]\n","\n","    if len(features) == 0:\n","        return df[target].mode()[0]\n","\n","    # Calculate parent entropy\n","    pos = (df[target] == '1').sum()\n","    neg = (df[target] == '0').sum()\n","\n","    total_count = pos + neg\n","\n","    total_count = total_count if total_count > 0 else 1\n","    pos = pos if pos > 0 else 1\n","    neg = neg if neg > 0 else 1\n","\n","    parent_entropy = (-(pos / total_count) * np.log2(pos / total_count)\n","                      - (neg / total_count) * np.log2(neg / total_count)) if total_count > 0 else 0\n","\n","    max_gain_feature = None\n","    max_gain_value = -np.inf\n","\n","    for feature in features:\n","        entropy_feature = calculate_entropy(df[feature], df[target])\n","        gain_feature = parent_entropy - entropy_feature\n","\n","        print(f\"Calculating gain for feature '{feature}':\")\n","        print(f\"Entropy: {entropy_feature}, Gain: {gain_feature}\")\n","\n","        if gain_feature > max_gain_value:\n","            max_gain_value = gain_feature\n","            max_gain_feature = feature\n","\n","    print(f\"\\nSelected feature '{max_gain_feature}' with maximum gain of {max_gain_value}\\n\")\n","\n","    tree_node = {max_gain_feature: {}}\n","\n","    splits = split_dataset(df, max_gain_feature)\n","\n","    remaining_features = [f for f in features if f != max_gain_feature]\n","\n","    for value, subset in splits.items():\n","        print(f\"Building subtree for '{max_gain_feature}={value}' subset:\")\n","\n","        pos_subset = (subset[target] == '1').sum()\n","        neg_subset = (subset[target] == '0').sum()\n","\n","        total_subset_count = pos_subset + neg_subset\n","\n","        total_subset_count = total_subset_count if total_subset_count > 0 else 1\n","        pos_subset = pos_subset if pos_subset > 0 else 1\n","        neg_subset = neg_subset if neg_subset > 0 else 1\n","\n","        subset_entropy = (-(pos_subset / total_subset_count) * np.log2(pos_subset / total_subset_count)\n","                          - (neg_subset / total_subset_count) * np.log2(\n","                    neg_subset / total_subset_count)) if total_subset_count > 0 else 0\n","\n","        print(f\"Subset size: {total_subset_count}, Positive labels: {pos_subset}, Negative labels: {neg_subset}\")\n","        print(f\"Subset entropy: {subset_entropy}\")\n","\n","        subtree_result = build_tree(subset, remaining_features, target)\n","        tree_node[max_gain_feature][value] = subtree_result\n","\n","    return tree_node\n","\n","features_list = ['AGE', 'INCOME', 'STUDENT', 'CREDIT']\n","decision_tree = build_tree(df, features_list, 'BUYS COMPUTER')\n","\n","print(\"\\nFinal Decision Tree:\")\n","print(decision_tree)\n","\n","from anytree import Node, RenderTree\n","\n","data =decision_tree\n","\n","def create_tree(data, parent=None):\n","    for key, value in data.items():\n","        node = Node(key, parent=parent)\n","        if isinstance(value, dict):\n","            create_tree(value, parent=node)\n","        else:\n","            Node(value, parent=node)\n","\n","root = Node(\"\\nRoot\")\n","create_tree(data, parent=root)\n","\n","for pre, _, node in RenderTree(root):\n","    print(f\"{pre}{node.name}\")\n","\n","\n","\n"]}]}